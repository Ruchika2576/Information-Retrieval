{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of IRM 2021 Exercise3 TEMPLATE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spUoQOmD5xzt"
      },
      "source": [
        "# Information Retrieval Exercise 3 Notebook \n",
        "\n",
        "\n",
        "This is the template notebook for Exercise 3. The specification for the exercise and the corresponding Exercise 3 Quiz submission instance are available on the Moodle page of the course.\n",
        "\n",
        "This exercise builds upon Exercise 2, and assumes that you are now familiar with concepts we have introduced in both Exercise 1 and Exercise 2, including:\n",
        " - [PyTerrier operators](https://pyterrier.readthedocs.io/en/latest/operators.html)\n",
        " - [Pyterrier apply transformers](https://pyterrier.readthedocs.io/en/latest/transformer.html)\n",
        " - [PyTerrier pt.Experiment()](https://pyterrier.readthedocs.io/en/latest/experiments.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huHo3UfD5z-A"
      },
      "source": [
        "## PyTerrier Setup\n",
        "\n",
        "First, let's install PyTerrier as usual. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1KQ6pjZ5dRb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e20843f-760d-48de-8131-910af35cd25c"
      },
      "source": [
        "!pip install python-terrier lightgbm==2.2.3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-terrier\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/bd/77d14471ff175b648369444715b7be7b49226068683e4b797cc1c0073ffe/python-terrier-0.6.0.tar.gz (86kB)\n",
            "\r\u001b[K     |███▊                            | 10kB 14.7MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 20kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 30kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 40kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 61kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 71kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 81kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: lightgbm==2.2.3 in /usr/local/lib/python3.7/dist-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.1.5)\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from python-terrier) (4.41.1)\n",
            "Collecting pyjnius~=1.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/b1/e33db12a20efe28b20fbcf4efc9b95a934954587cd7aa5998987a22e8885/pyjnius-1.3.0-cp37-cp37m-manylinux2010_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 31.1MB/s \n",
            "\u001b[?25hCollecting matchpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/25/6b8fa5846476c2d56856a4926fda859b218656b14571ace76fbcd1d39986/matchpy-0.5.4-py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from python-terrier) (0.0)\n",
            "Collecting deprecation\n",
            "  Downloading https://files.pythonhosted.org/packages/02/c3/253a89ee03fc9b9682f1541728eb66db7db22148cd94f89ab22528cd1e1b/deprecation-2.1.0-py2.py3-none-any.whl\n",
            "Collecting chest\n",
            "  Downloading https://files.pythonhosted.org/packages/18/66/b883b9a26cd2f777dd04b7eedc842d31ea1567b7709b049d46eca418501e/chest-0.2.3.tar.gz\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from python-terrier) (2.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.0.1)\n",
            "Collecting nptyping\n",
            "  Downloading https://files.pythonhosted.org/packages/8e/d5/3331d6fe411c0287ef4b028ded3355c4fc10956f4c0fbe5a4415fdd33dc8/nptyping-1.4.2-py3-none-any.whl\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.7/dist-packages (from python-terrier) (8.8.0)\n",
            "Collecting ir_datasets>=0.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/9c/e35d3fa08b65cf9db740ea04a0b48fde16d94a093368ec6e097f3ccfd00b/ir_datasets-0.4.0-py3-none-any.whl (206kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 41.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from python-terrier) (2.11.3)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from python-terrier) (0.10.2)\n",
            "Collecting ir_measures>=0.1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/74/15/29146d203e05d63407402a8a254992e41352283ec586359de1d320b608a0/ir_measures-0.1.4.tar.gz\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightgbm==2.2.3) (0.22.2.post1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->python-terrier) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->python-terrier) (2.8.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from pyjnius~=1.3.0->python-terrier) (0.29.23)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pyjnius~=1.3.0->python-terrier) (1.15.0)\n",
            "Collecting multiset<3.0,>=2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a8/12/813a649f5bc9801865dc6cda95b8f169f784d996322db192907ebe399064/multiset-2.1.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deprecation->python-terrier) (20.9)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from chest->python-terrier) (1.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->python-terrier) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->python-terrier) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->python-terrier) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->python-terrier) (2021.5.30)\n",
            "Collecting typish>=1.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/a7/83e450157d1613be0725821f8bd8aadab22217fa5dac4795dcfb9408be95/typish-1.9.2-py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.0MB/s \n",
            "\u001b[?25hCollecting zlib-state>=0.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/05/95df36be761a5ff85a39b438d87937f02762c19fea95c0f10b679a259f14/zlib_state-0.1.3-cp37-cp37m-manylinux2010_x86_64.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.5MB/s \n",
            "\u001b[?25hCollecting lxml>=4.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/c0/d0526314971fc661b083ab135747dc68446a3022686da8c16d25fcf6ef07/lxml-4.6.3-cp37-cp37m-manylinux2014_x86_64.whl (6.3MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3MB 41.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from ir_datasets>=0.3.2->python-terrier) (4.6.3)\n",
            "Collecting warc3-wet>=0.2.3\n",
            "  Downloading https://files.pythonhosted.org/packages/78/de/017a6bc2e3ba1ad912a08501f58414dd9e8503da1d6239aad548631777ad/warc3_wet-0.2.3-py3-none-any.whl\n",
            "Collecting pyyaml>=5.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 35.1MB/s \n",
            "\u001b[?25hCollecting ijson>=3.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/0c/e3b7bf52e23345d5f9a6a3ff6de0cad419c96491893ab60cbbe9161644a8/ijson-3.1.4-cp37-cp37m-manylinux2010_x86_64.whl (126kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 51.9MB/s \n",
            "\u001b[?25hCollecting lz4>=3.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/52/151c815a486290608e4dc6699a0cfd74141dc5191f8fe928e7d1b28b569e/lz4-3.1.3-cp37-cp37m-manylinux2010_x86_64.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 38.9MB/s \n",
            "\u001b[?25hCollecting warc3-wet-clueweb09>=0.2.5\n",
            "  Downloading https://files.pythonhosted.org/packages/9f/c1/dd817bf57e0274dacb10e0ac868cb6cd70876950cf361c41879c030a2b8b/warc3-wet-clueweb09-0.2.5.tar.gz\n",
            "Collecting trec-car-tools>=2.5.4\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/e2/da4e895e5ad519f9f6aa464530dd482c7132c92a55cf178b8132e84b5c1d/trec_car_tools-2.5.4-py3-none-any.whl\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->python-terrier) (2.0.1)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->python-terrier) (0.5.1)\n",
            "Collecting pytrec-eval-terrier==0.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/f0/582f00ea388bc191d1f1278e5cfabc95be177480220a1af5f1231732f167/pytrec_eval_terrier-0.5.1-cp37-cp37m-manylinux2010_x86_64.whl (291kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 38.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->deprecation->python-terrier) (2.4.7)\n",
            "Collecting cbor>=1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/99/01c6a987c920500189eb74a291bd3a388e6c7cf85736bb6b066d9833315e/cbor-1.0.0.tar.gz\n",
            "Building wheels for collected packages: python-terrier, wget, chest, ir-measures, warc3-wet-clueweb09, cbor\n",
            "  Building wheel for python-terrier (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-terrier: filename=python_terrier-0.6.0-cp37-none-any.whl size=93214 sha256=c2edc232f1f16a55c672cd417821a5d44c84f640af0a1919c56129bdc25db82f\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/8d/91/58da79fd0a2850843b7e8c6097a52f9ff7aa85953cc9c8d27f\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9675 sha256=652219a82cd8ca78fdd5ffb08a94b544ff08ba66113e429c04ced7e5617683f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "  Building wheel for chest (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chest: filename=chest-0.2.3-cp37-none-any.whl size=7635 sha256=13d2f50ea16e18eb209692e97439ac782ba2b10d653e225548d2fab41993d072\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/52/97/3f0eb272609dc1b7a20fb678a45003301b51f03cf766f6237f\n",
            "  Building wheel for ir-measures (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ir-measures: filename=ir_measures-0.1.4-cp37-none-any.whl size=40003 sha256=d1cdbccd63248b552e49abd345869996a37a1bf460be0e05a2c2e0c11be0edff\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/c1/67/4dfa24e5ea066cc09694d001b2bc9ecbf9a3139d69847150a4\n",
            "  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-cp37-none-any.whl size=18922 sha256=7d193b0ee5c4059c416aba2cb111694635aa3ea0d54ed3dd4de3f75ea5364c71\n",
            "  Stored in directory: /root/.cache/pip/wheels/09/da/a9/ec9816edf7f789eab3fea2e57abe37bf7d6ab65f8ef8ee7f31\n",
            "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cbor: filename=cbor-1.0.0-cp37-cp37m-linux_x86_64.whl size=51256 sha256=99d49d9d57e405356658c1a3c94d177899f631f7f985ae28bfd6624fabfd327f\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/5c/a5/e6d629446a6a687ba328c55f1589234c29b99ef35b1a65dbaa\n",
            "Successfully built python-terrier wget chest ir-measures warc3-wet-clueweb09 cbor\n",
            "Installing collected packages: wget, pyjnius, multiset, matchpy, deprecation, chest, typish, nptyping, zlib-state, lxml, warc3-wet, pyyaml, ijson, lz4, warc3-wet-clueweb09, cbor, trec-car-tools, ir-datasets, pytrec-eval-terrier, ir-measures, python-terrier\n",
            "  Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed cbor-1.0.0 chest-0.2.3 deprecation-2.1.0 ijson-3.1.4 ir-datasets-0.4.0 ir-measures-0.1.4 lxml-4.6.3 lz4-3.1.3 matchpy-0.5.4 multiset-2.1.1 nptyping-1.4.2 pyjnius-1.3.0 python-terrier-0.6.0 pytrec-eval-terrier-0.5.1 pyyaml-5.4.1 trec-car-tools-2.5.4 typish-1.9.2 warc3-wet-0.2.3 warc3-wet-clueweb09-0.2.5 wget-3.2 zlib-state-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDst0SPaLY0U"
      },
      "source": [
        "Let's start PyTerrier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-6kc18m5dRk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7afa7de-1e95-47e7-98ac-e78558756107"
      },
      "source": [
        "import pyterrier as pt\n",
        "if not pt.started():\n",
        "  pt.init()\n",
        "\n",
        "# we require a specific version of LightGBM for this exercise\n",
        "import lightgbm\n",
        "assert lightgbm.__version__ == '2.2.3'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "terrier-assemblies 5.5  jar-with-dependencies not found, downloading to /root/.pyterrier...\n",
            "Done\n",
            "terrier-python-helper 0.0.5  jar not found, downloading to /root/.pyterrier...\n",
            "Done\n",
            "PyTerrier 0.6.0 has loaded Terrier 5.5 (built by craigmacdonald on 2021-05-20 13:12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxAlgu_NCclH"
      },
      "source": [
        "# patch location of topics and qrels\n",
        "def _filter_on_qid_type(self, component, variant):\n",
        "  import pandas as pd\n",
        "  if component == \"topics\":\n",
        "    data = self.get_topics(\"all\")\n",
        "  elif component == \"qrels\":\n",
        "    data = self.get_qrels(\"all\")\n",
        "  qid2type = pd.read_csv(\"http://mirror.ir-datasets.com/79737768b3be1aa07b14691aa54802c5\", names=[\"qid\", \"type\"], sep=\" \")\n",
        "  qid2type[\"qid\"] = qid2type.apply(lambda row: row[\"qid\"].split(\"-\")[1], axis=1)\n",
        "  rtr = data.merge(qid2type[qid2type[\"type\"] == variant], on=[\"qid\"])\n",
        "  if len(rtr) == 0:\n",
        "    raise ValueError(\"No such topic type '%s'\" % variant)\n",
        "  rtr.drop(columns=['type'], inplace=True)\n",
        "  return (rtr, \"direct\")\n",
        "\n",
        "dataset = pt.get_dataset(\"trec-wt-2004\")\n",
        "for t in [\"np\", \"td\", \"hp\"]:\n",
        "  dataset.locations[\"qrels\"][t] = _filter_on_qid_type\n",
        "  dataset.locations[\"topics\"][t] = _filter_on_qid_type\n",
        "dataset.locations[\"qrels\"][\"all\"] = ('04.qrels.web.mixed.txt', \"http://www.dcs.gla.ac.uk/~craigm/04.qrels.web.mixed.txt\")\n",
        "dataset.locations[\"topics_prefixed\"][\"all\"] = ('Web2004.query.stream.trecformat.txt', \"http://www.dcs.gla.ac.uk/~craigm/Web2004.query.stream.trecformat.txt\", \"trec\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3BwH1hz5dRl"
      },
      "source": [
        "## Index, Topics & Qrels for Exercise 3\n",
        "\n",
        "You will need your login & password credentials from Exercise 2. We will be using again the \"50pct\" and the \"trec-wt-2004\" datasets from Exercise 2.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd5zaOrL5dRm"
      },
      "source": [
        "UNAME = \"2576183s\"\n",
        "PWORD = \"9c8d7804\"\n",
        "\n",
        "from pyterrier.datasets import STANDARD_TERRIER_INDEX_FILES, RemoteDataset\n",
        "\n",
        "# we will again be using the \"50pct\" and \"trec-wt-2004\" datasets\n",
        "Fiftypct = pt.get_dataset(\"50pct\",  user=UNAME, password=PWORD)\n",
        "dotgov_topicsqrels = pt.get_dataset(\"trec-wt-2004\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAW4E_7m7na0"
      },
      "source": [
        "On the other hand, you will be using a slightly updated index for Exercise 3. It is a bit bigger than the Exercise 2 index, hence it takes about 2-3 minutes to download to Colab. \n",
        "\n",
        "We also remove the Ex2 index, if it is found (this will only apply if you are not running on Colab). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XYmUmh25dRl"
      },
      "source": [
        "def removeEx2Index():\n",
        "  import os\n",
        "  indexdir = os.path.join(Fiftypct.corpus_home, \"index\")\n",
        "  if os.path.exists(os.path.join(indexdir, \"data.properties\")) and not os.path.exists(os.path.join(indexdir, \"data-pagerank.oos\")):\n",
        "    #this branch only occurs if the index from IRM Ex2 is found  \n",
        "    print(\"WARNING: I have detected and removed an Ex2 index - if you are still working on Ex2, results will be identical, but \" +\n",
        "          \"querying time will be a bit longer\")\n",
        "    print(\"To restore the original Ex2 index, you can delete %s and rerun the Ex2 notebook\" % indexdir)\n",
        "    import shutil\n",
        "    shutil.rmtree(indexdir)\n",
        "\n",
        "removeEx2Index()\n",
        "\n",
        "indexref = Fiftypct.get_index(variant=\"ex2\")\n",
        "index = pt.IndexFactory.of(indexref)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSWbTO8d5dRl"
      },
      "source": [
        "Let's check out the new index. Compared to the index we used for Exercise 2, you can see that this index has `Field Names: [TITLE, ELSE]`, which means that we can provide statistics about how many times each term occurs in the title of each document (the \"TITLE\" field), vs the rest of the document (the \"ELSE\" field). Refer to Lecture 8 for more information about fields.\n",
        "\n",
        "Let's also display the keys in the meta index - this is the metadata that we have stored for each document. You can see that we are storing the \"url\" and the \"body\" (content) of the document. These will particularly come in handy for Q2 and Q3 of Exercise 3, respectively.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp6-MDzY5dRl"
      },
      "source": [
        "print(index.getCollectionStatistics())\n",
        "print(\"In the meta index: \" + str(index.getMetaIndex().getKeys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdMiyeZ177AK"
      },
      "source": [
        "Finally, these are all of the topics and qrels (including the training and validation datasets) that you will need to conduct Exercise 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKi5ACEj5dRm"
      },
      "source": [
        "tr_topics = Fiftypct.get_topics(\"training\")\n",
        "va_topics = Fiftypct.get_topics(\"validation\")\n",
        "\n",
        "tr_qrels = Fiftypct.get_qrels(\"training\")\n",
        "va_qrels = Fiftypct.get_qrels(\"validation\")\n",
        "\n",
        "test_topics = dotgov_topicsqrels.get_topics(\"hp\")\n",
        "test_qrels = dotgov_topicsqrels.get_qrels(\"hp\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hWAMSAK5dRm"
      },
      "source": [
        "## Baseline Setup\n",
        "\n",
        "We introduce here the BatchRetrieve for our baseline. Note that:\n",
        " - We are using PL2 as our weighting model to generate the sample (the candidate set of documents to re-rank).\n",
        " - We expose more document metadata, namely \"url\" and \"body\" for each document retrieved, which you will need to deploy your two new features. \n",
        " - By setting `verbose=True`, we display a progress bar while retrieval executes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3atqw8q35dRn"
      },
      "source": [
        "firstpassUB = pt.BatchRetrieve(index, wmodel=\"PL2\", metadata=[\"docno\", \"url\", \"body\"], verbose=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iez_aX9D1pXI"
      },
      "source": [
        "Let's see the resulting output - you can see that there are now \"url\" and \"body\" attributed for each retrieved document. (We also display a progress bar, enabled by the `verbose=True`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkE-UBRd5dRn"
      },
      "source": [
        "firstpassUB.search(\"chemical reactions\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVQGefXx5dRo"
      },
      "source": [
        "# Standard list of features\n",
        "\n",
        "Let's introduce the list of features we need to deploy a baseline learning-to-rank approach."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMG6P1cG5dRo"
      },
      "source": [
        "pagerankfile = indexref.toString().replace(\".properties\", \"-pagerank.oos\")\n",
        "features = [\n",
        "    \"SAMPLE\", #ie PL2\n",
        "    \"WMODEL:SingleFieldModel(BM25,0)\", #BM25 title\n",
        "    \"QI:StaticFeature(OIS,%s)\" % pagerankfile,\n",
        "]\n",
        "\n",
        "stdfeatures = pt.FeaturesBatchRetrieve(index, features, verbose=True)\n",
        "stage12 = firstpassUB >> stdfeatures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oFWy0u9143O"
      },
      "source": [
        "This is our feature set. We will be using FeaturesBatchRetrieve to compute these extra features on the fly. Let's see the output. You can see that there is now a \"features\" column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb-InOIq8Xc7"
      },
      "source": [
        "stage12.search(\"chemical reactions\").head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNoja4352Pvt"
      },
      "source": [
        "Let's look in more detail at the features. It is clear that there are 3 numbers for each document. The first is the PL2 score (1.27555456e+01 == 12.7555), the second is the BM25 score, and the third is the PageRank (a link analysis feature - discussed in more detail in Lecture 10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6Horkb-2KYT"
      },
      "source": [
        "stage12.search(\"chemical reactions\").head(1).iloc[0][\"features\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYoJRrJR4oTL"
      },
      "source": [
        "# Q1\n",
        "\n",
        "You now have everyting you need to attempt Q1. You will need to refer to the specification, and to PyTerrier's [learning to rank documentation](https://pyterrier.readthedocs.io/en/latest/ltr.html).\n",
        "\n",
        "You should use a LightGBM LambdaMART implementation (*not* XGBoost), instantiated using the configuration suggested in the PyTerrier documentation.\n",
        "\n",
        "Hints:\n",
        " - You will need to use the provided separate “training” and “validation” topic sets and qrels to train the learning-to-rank.\n",
        " - There is no need to vary the configuration of LightGBM from that in the documentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNNPtj7XHsTs"
      },
      "source": [
        "#YOUR SOLUTION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh0whrbS9-xu"
      },
      "source": [
        "# Q2 - URL Length Features\n",
        "\n",
        "In this block, please provide your code for Q2 concerning your two URL Length features, namely URL Length by counting slashes (URL-slashes) and URL Length through using the type of the URL (URL-type). There are different possible URL length features that you could implement (see specification). Do carefully read and follow the Exercise 3 specification before starting the implementation of the features.\n",
        "\n",
        "Some hints:\n",
        "\n",
        " - You will need to use a [pt.apply function](https://pyterrier.readthedocs.io/en/latest/apply.html) for computing your URL feature(s). The dataframe of results obtained from the upstream transformer has all of the information you need.\n",
        "\n",
        " - You can use a `**` operator for combining feature sets.\n",
        "\n",
        " - Refer to the PyTerrier learning to rank documentation  concerning `features_importances_` for obtaining feature importances.\n",
        "\n",
        " - You may wish to refer to Python's [`urlparse()`](https://docs.python.org/3/library/urllib.parse.html) function.\n",
        "\n",
        " - Use Python assertions to test that your feature implmentation(s) give the expected results. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeIqqLYtxB_h"
      },
      "source": [
        "## Q2 (a) URL-Slashes Feature\n",
        "\n",
        "In this block you should define your URL-Slashes feature, and test it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiNTl3HbxZwZ"
      },
      "source": [
        "#YOUR SOLUTION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_ugoAqhxbGM"
      },
      "source": [
        "#### (i) URL-Slashes as a PL2 re-ranker\n",
        "\n",
        "Now you should evaluate your URL-slashes score by re-ranking PL2. You can now answer the corresponding quiz questions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVNHsX_ixoYS"
      },
      "source": [
        "#YOUR SOLUTION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGoCpq3QxptA"
      },
      "source": [
        "#### (ii) URL-Slashes within an LTR model\n",
        "\n",
        "Now you should evaluate your URL-slashes score as a feature within a new learned model. You can now answer the corresponding quiz questions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leH5uh4xx2el"
      },
      "source": [
        "#YOUR SOLUTION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo3mba6sxLqz"
      },
      "source": [
        "## Q2 (b) URL Type Feature\n",
        "\n",
        "In this block you should define your URL Type feature and test it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgSh7TmmyIWN"
      },
      "source": [
        "#YOUR SOLUTION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VugAPVF8yIWN"
      },
      "source": [
        "#### (i) URL Type as a PL2 re-ranker\n",
        "\n",
        "Now you should evaluate your URL type score by re-ranking PL2. You can now answer the corresponding quiz questions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8L4AVuVyIWO"
      },
      "source": [
        "#YOUR SOLUTION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HuuiWUSyIWO"
      },
      "source": [
        "#### (ii) URL Type within an LTR model\n",
        "\n",
        "Now you should evaluate your URL type score as a feature within a new learned model. You can now answer the corresponding quiz questions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxBUGnDzyIWO"
      },
      "source": [
        "#YOUR SOLUTION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7LtU56pC9VG"
      },
      "source": [
        "# Q3 Proximity Search Feature\n",
        "\n",
        "Now you will implement a new query-dependent feature, using the MinDist() function, as discussed in the specification. Do carefully read the specification before starting the implementation.\n",
        "\n",
        "Hints:\n",
        " - Again, remember to use assertions to test your feature implementations.\n",
        " - Refer to the PyTerrier learning to rank documentation concerning features_importances_ for obtaining feature importances\n",
        "\n",
        "As mentioned in the specification, you should implement a function called avgmindist(), which takes the text of the query and the text of the document, and returns a score for the document, i.e. it must conform to the following Python specification:\n",
        "```python\n",
        "def avgmindist(query : str, document : str) -> float\n",
        "```\n",
        "\n",
        "NB: There are particular specific requirements for your implementations of MinDist() and avgmindist() that are detailed in the specification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiN0A-g7L0qz"
      },
      "source": [
        "#YOUR AVGMINDIST IMPLEMENTATION\n",
        "\n",
        "def avgmindist(query : str, document : str) -> float\n",
        "  #update your implementation here.\n",
        "  return 0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpCKKQBRL4o4"
      },
      "source": [
        "You should test your impementation yourself, however to allow us to verify your implementation, we have created 9 testcases. Please run `run_test_cases()` and use its responses to answer the relevant quiz questions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnDXgIRlDIDr"
      },
      "source": [
        "#DO NOT ALTER THIS CELL\n",
        "TEST_CASES = [\n",
        "  ('fermilab directory', 45, 567257), #1\n",
        "  ('webcam', 45, 567257), #2\n",
        "  ('DOM surface', 384034, 388292), #3\n",
        "  ('DOM surface', 45, 384034), #4\n",
        "  ('DOM surface document', 388292, 384034), #5\n",
        "  ('DOM software AMANDA', 639302, 384034), #6\n",
        "  ('fermilab directory', 388292, 384034), #7\n",
        "  ('trigger data', 596532, 639302), #8\n",
        "  ('underlying hardware', 384034, 333649) #9\n",
        "]\n",
        "\n",
        "def run_test_cases():\n",
        "  docno=0\n",
        "  body=3\n",
        "  for i, (query, docid1, docid2) in enumerate(TEST_CASES):\n",
        "    meta1 = index.getMetaIndex().getAllItems(docid1)\n",
        "    meta2 = index.getMetaIndex().getAllItems(docid2)\n",
        "    s1 = avgmindist(query, meta1[body])\n",
        "    s2 = avgmindist(query, meta2[body])\n",
        "    if s1 > s2:\n",
        "      result = meta1[docno]\n",
        "      cmpD = \"%s > %s\" % (meta1[docno],meta2[docno])\n",
        "    elif s2 > s1:\n",
        "      result = meta2[docno]\n",
        "      cmpD = \"%s > %s\" % (meta2[docno],meta1[docno])\n",
        "    else:\n",
        "      result = \"EQUAL\"\n",
        "      cmpD = \"%s == %s\" % (meta1[docno],meta2[docno])\n",
        "    print(\"TEST CASE %d result %s \" % (i+1, result))\n",
        "\n",
        "run_test_cases()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp57S1vTMiB5"
      },
      "source": [
        "You should now integrate your avgmindist() function into a new LTR model, and compare its MAP & P@5 performance to the LTR baseline. You can now answer the corresponding quiz questions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaFXG5_PMnRN"
      },
      "source": [
        "#YOUR SOLUTION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-akCsk7tDoOs"
      },
      "source": [
        "# Q4 A 5-feature Learning-to-Rank Model\n",
        "\n",
        "You will now experiment with the LightGBM LambdaMART technique where you include both your added features (URL Type and AvgMinDist) along the 3 initial features inc PL2 sample (5 features in total). \n",
        "\n",
        "You need to learn a *new* model when using your final selection of 5 features.\n",
        "\n",
        "Evaluate the performance of your resulting LTR system in comparison to the LTR baseline and answer the quiz questions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25AQ4Mn2QAqg"
      },
      "source": [
        "#YOUR SOLUTION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n_C4m5WEnMz"
      },
      "source": [
        "# That's all Folks\n",
        "\n",
        "**Submission Instructions:** Complete this notebook. All your answers to Exercise 3 must be submitted on the Exercise 3 Quiz instance on Moodle with your completed notebook (showing both your solutions and the results of their executions).\n",
        "\n",
        "\n",
        "Your answers to the Quiz questions along with your .ipynb notebook file (showing code and outputs) must be submitted by **Friday 18th June 2021, 4:30pm**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ammXItAGm2UR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}